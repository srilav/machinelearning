{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M3_AST_02_BinaryClassification_and_PerformanceMetrics_C.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilav/machinelearning/blob/main/M3_AST_02_BinaryClassification_and_PerformanceMetrics_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps9llghv8jX1"
      },
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "## A program by IISc and TalentSprint\n",
        "### Assignment 2: Binary Classification and Performance Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeP1PAXf8jYD"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkwaW3k58jYG"
      },
      "source": [
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "* learn about Classification tasks in Machine learning\n",
        "* perform Logistic Regression, Softmax Regression\n",
        "* learn the appropriate performance metrics according to use case\n",
        "* have an understanding of Decision Boundaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzIWfoFc-mis"
      },
      "source": [
        "## Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KfDhYd1yUIx"
      },
      "source": [
        "### Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-QzRVapVOow"
      },
      "source": [
        "**Classification** refers to a predictive modeling problem where a class label is predicted for a given example of input data.\n",
        "\n",
        "**Examples include:**\n",
        "\n",
        "* Email spam detection (spam or not).\n",
        "* Churn prediction (churn or not).\n",
        "* Conversion prediction (buy or not).\n",
        "\n",
        "**Binary classification** refers to those classification tasks that have two class labels.\n",
        "\n",
        "**Logistic Regression** is a Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable is a binary variable that contains data coded as 1 (yes, success, etc.) or 0 (no, failure, etc.). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zU4iSDHpQMB"
      },
      "source": [
        "### Implementing Binary Classification with Logistic Regression "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg_NkkELpZKB"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScK34HRop_Uf"
      },
      "source": [
        "In this example, we will be using \"Social_Network_Ads\" dataset. \n",
        "\n",
        "The variable descriptions are as follows:\n",
        "\n",
        "* Age\n",
        "* EstimatedSalary\n",
        "\n",
        "The target feature is:\n",
        "* Purchased\n",
        "\n",
        "**Problem Statement:** To predict if a person will purchase an item based on age and estimated salary. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YzfoPvJDiTX"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjoZJWGErxGf"
      },
      "source": [
        "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBPPuGmBlDIN",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "  \n",
        "notebook= \"M3_AST_02_BinaryClassification_and_PerformanceMetrics_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")  \n",
        "    ipython.magic(\"sx wget https://cdn.iisc.talentsprint.com/CDS/Datasets/Social_Network_Ads.csv\")\n",
        "    ipython.magic(\"sx wget https://cdn.iisc.talentsprint.com/aiml/Experiment_related_data/diabetes.csv\")\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "    \n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None        \n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "    \n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None   \n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://cds.iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "    \n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional: \n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional  \n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "  \n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "  \n",
        "  \n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "  \n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError \n",
        "    else: \n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getId():\n",
        "  try: \n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup \n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup() \n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWv5Dh4iO3Pj"
      },
      "source": [
        "### Importing required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ljIHCqCO3mk"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x4tygU7rw0u"
      },
      "source": [
        "#### Importing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_14Ruksx4zx"
      },
      "source": [
        "df = pd.read_csv('Social_Network_Ads.csv')\n",
        "X = df.iloc[:, 1].values # estimated salary\n",
        "y = df.iloc[:, -1].values\n",
        "X = X.reshape(-1, 1)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz_y_tzzrxAZ"
      },
      "source": [
        "#### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwmIhomc-igk"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j-ECM1T-i2p"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyuA7_JzSN5-"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lcizce69SRPe"
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00b_DUmXSRYl"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppSxsQ6pQbjO"
      },
      "source": [
        "#### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCFtgPISPYbU"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7Qf5eY1SfVn"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUrZNVyGSffd"
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZqNg1ErQpt_"
      },
      "source": [
        "#### Training the Logistic Regression model on the Training set\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmowAS_ePasE"
      },
      "source": [
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75AUfSTKSvFe"
      },
      "source": [
        "#### Predicting a new test instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJQOOQpXQ2-m"
      },
      "source": [
        "print(classifier.predict(sc.transform([[87000]])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dLORN2ZSytH"
      },
      "source": [
        "#### Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvKLpe0oSy4b"
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRZhKV_8hosC"
      },
      "source": [
        "### Model Evaluation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gq0o0s1hrEr"
      },
      "source": [
        "To evaluate the performance of a classification model, the following metrics are used:\n",
        "\n",
        "* Confusion matrix\n",
        "  * Accuracy\n",
        "  * Precision\n",
        "  * Recall\n",
        "  * F1-Score\n",
        "* ROC curve\n",
        "* AUROC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erCaVXheUca3"
      },
      "source": [
        "#### Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0spQOwVdl6r"
      },
      "source": [
        "* **Confusion matrix:**  is a table that is used to describe the performance of a classification model on a set of test data for which the true values are known. \n",
        "\n",
        "  * **true positive** for correctly predicted event values.\n",
        "  * **false positive** for incorrectly predicted event values.\n",
        "  * **true negative** for correctly predicted no-event values.\n",
        "  * **false negative** for incorrectly predicted no-event values.\n",
        "* **Accuracy:** it is the ratio of the number of correct predictions to the total number of input samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4J9t7uyUbmX"
      },
      "source": [
        "# Creating a confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghMYzkSFtbix"
      },
      "source": [
        "This Confusion Matrix tells us that there were 81 correct predictions and 19 incorrect ones.\n",
        "\n",
        "* True Positive: 66\n",
        "* True Negative: 15\n",
        "* False Positive: 2\n",
        "* False Negative: 17"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnKMEUwPiER0"
      },
      "source": [
        "#### Precision-Recall Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ_xgAFUiEeq"
      },
      "source": [
        "* **Precision:** summarizes the fraction of examples assigned the positive class that belongs to the positive class.\n",
        "\n",
        "    Precision = $\\mathbf{\\frac{TruePositive}{TruePositive + FalsePositive}}$\n",
        "\n",
        "* **Recall:** summarizes how well the positive class was predicted and is the same calculation as sensitivity.\n",
        "\n",
        "   Recall = $\\mathbf{\\frac{TruePositive}{TruePositive + FalseNegative}}$\n",
        "\n",
        "* **F1-score:** precision and recall can be combined into a single score that seeks to balance both concerns, called the F-score or the F-measure.\n",
        "  \n",
        "   F1-score = $\\mathbf{\\frac{2*Precision*Recall}{Precision+Recall}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV0iHWlKbU5l"
      },
      "source": [
        "##### Plotting precision-recall curve using sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btDWhBYCDsf2"
      },
      "source": [
        "# Use sklearn to plot precision-recall curves\n",
        "\n",
        "from sklearn.metrics import plot_precision_recall_curve\n",
        "\n",
        "plot_precision_recall_curve(classifier, X_test, y_test, name = 'Logistic Regression')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qE9UERaaM8W"
      },
      "source": [
        "The above diagram shows the blue line as precision-recall curve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi0Hm4JGiYPk"
      },
      "source": [
        "### ROC-AUC curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyOwoo7snM4u"
      },
      "source": [
        "A ROC curve is a diagnostic plot for summarizing the behavior of a model by calculating the false positive rate and true positive rate for a set of predictions by the model under different thresholds.\n",
        "\n",
        "Area Under Curve (AUC) is one of the most widely used metrics for evaluation. It is used for binary classification problems.\n",
        "\n",
        "AUC has a range of [0, 1]. The greater the value, the better is the performance of our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmcWOD9UbCFP"
      },
      "source": [
        "#### Plotting the ROC-AUC curve for Logistic Regression algorithm using matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7N2-3HhtFQVm"
      },
      "source": [
        "# roc_curve() computes the ROC for the classifier and returns the FPR, TPR, and threshold values\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "classifier.fit(X_train, y_train)\n",
        "pred_prob1 = classifier.predict_proba(X_test)\n",
        "\n",
        "# roc curve for models\n",
        "fpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob1[:,1], pos_label=1)\n",
        "\n",
        "\n",
        "# roc curve for tpr = fpr \n",
        "random_probs = [0 for i in range(len(y_test))]\n",
        "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGwFRT2bE5kq"
      },
      "source": [
        "plt.style.use('seaborn')\n",
        "\n",
        "# plot roc curves\n",
        "plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='Logistic Regression')\n",
        "\n",
        "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
        "# title\n",
        "plt.title('ROC curve')\n",
        "# x label\n",
        "plt.xlabel('False Positive Rate')\n",
        "# y label\n",
        "plt.ylabel('True Positive rate')\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('ROC',dpi=300)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYmER6qRtzz1"
      },
      "source": [
        "The above diagram shows:\n",
        "\n",
        "ROC curve: is the orange dotted line\n",
        "\n",
        "AUROC: is the area under the orange dotted line\n",
        "\n",
        "The blue dotted line is the reference line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0biP4B7XfVi"
      },
      "source": [
        "Please refer to the given [link](https://heartbeat.fritz.ai/evaluation-metrics-for-machine-learning-models-d42138496366) for further information on Performance metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV4AqMlfy_az"
      },
      "source": [
        "### Example: Predicting Diabetes with Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLcNsXLtIFQe"
      },
      "source": [
        "Let us now apply the above learnings to perform a logistic regression using a 'UCI PIMA Indian Diabetes' dataset.\n",
        "\n",
        " * Fit the model\n",
        " * Do the prediction\n",
        " * Plot the ROC-AUC curve for the Logistic Regression algorithm\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLe2mZvl9gm8"
      },
      "source": [
        "#### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88C2CvR63Luc"
      },
      "source": [
        "In this example, we will be using the \"UCI PIMA Indian Diabetes\" dataset.\n",
        "\n",
        "The datasets consist of several medical predictor variables and one target variable, Outcome. Predictor variables include the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n",
        "\n",
        "The variable descriptions are as follows:\n",
        "\n",
        "* Pregnancies: Number of Pregnancies\n",
        "* Glucose: Plasma glucose concentration over 2 hours in an oral glucose tolerance test\n",
        "* Blood pressure: Diastolic blood pressure (mm Hg)\n",
        "* SkinThickness: Triceps skinfold thickness (mm)\n",
        "* Insulin: 2-Hour serum insulin (mu U/ml)\n",
        "* BMI: Body mass index (weight in kg/(height in m)2)\n",
        "* DiabetesPedigreeFunction: Diabetes pedigree function (a function which scores likelihood of diabetes based on family history)\n",
        "* Age: Age (years)\n",
        "* Outcome: Class variable (0 if non-diabetic, 1 if diabetic)\n",
        "\n",
        "Problem statement:\n",
        "\n",
        "We will be using this dataset to predict if a person has diabetes or not using the medical attributes provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bragT22u9dFV"
      },
      "source": [
        "#### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygezgrUE3L9I"
      },
      "source": [
        "DF = pd.read_csv('diabetes.csv')\n",
        "print(DF.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrnSNpIK9nMs"
      },
      "source": [
        "#### Finding if there are any null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_Xk1F_O8JZD"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAHBKXc63MGH"
      },
      "source": [
        "#### Training our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nONFn5s7BSZo"
      },
      "source": [
        "# Separating the data into independent and dependent variables\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohpa54Ey3MV0"
      },
      "source": [
        "#### Splitting the data into training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhLdN-k-3Mdu"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RQF--gm3MmN"
      },
      "source": [
        "#### Training the Logistic Regression model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhK7n28I3My_"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_WlbEhI3M8A"
      },
      "source": [
        "#### Training/Fitting the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhjpnE2a3NES"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_nOuS5w3NL5"
      },
      "source": [
        "#### Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSJrzGgn3NT2"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC26I6QlCV2X"
      },
      "source": [
        "#### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--ycunMgCWCr"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhq0Qh13zAob"
      },
      "source": [
        "#### Plotting the ROC curve for Logistic Regression algorithm using matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAGVagUZIsbt"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0zX9rflZ95t"
      },
      "source": [
        "###  Softmax Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd4f0fdcrwQt"
      },
      "source": [
        "The **Softmax regression** is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1.\n",
        "\n",
        "It is also called **multinomial logistic regression.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pzGTIwxfs1T"
      },
      "source": [
        "Performing Softmax Regression on the above dataset \"Social_Network_Ads\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6sz_oUvO_ni"
      },
      "source": [
        "X = df.iloc[:, :-1].values # considering age,estimated salary\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktJUEhjQaaZM"
      },
      "source": [
        "#### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKpju6jeWWps"
      },
      "source": [
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW3_xn-zWWpu"
      },
      "source": [
        "#### Training the Softmax Regression model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_FJ6vU1WWpv"
      },
      "source": [
        "softmax_reg = LogisticRegression(multi_class='multinomial', # switch to Softmax Regression\n",
        "                                     solver='lbfgs', # handle multinomial loss, L2 penalty\n",
        "                                     C=10)\n",
        "softmax_reg.fit(X, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DLVGNOHWWpv"
      },
      "source": [
        "#### Predicting a new result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_gz1YF1fbY9"
      },
      "source": [
        "softmax_reg.predict(sc.transform([[30,87000]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4Gajh2DXNj2"
      },
      "source": [
        "softmax_reg.predict_proba(sc.transform([[30,87000]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AS_oGgsTWg8"
      },
      "source": [
        "### Decision Boundary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi44DjJUTgvl"
      },
      "source": [
        "In classification problems with two or more classes, a decision boundary is a hypersurface that separates the underlying vector space into sets, one for each class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTfA1CGIT3Av"
      },
      "source": [
        "#### Creating Dummy Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6Ncu968Evs0"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_samples=200, n_features=2, n_informative=2, n_redundant=0, n_classes=2, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb4YBLrgVYh-"
      },
      "source": [
        "#### Creating Decision Boundary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7ToIkZ-Svu-"
      },
      "source": [
        "import matplotlib.gridspec as gridspec\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "gs = gridspec.GridSpec(3, 2)\n",
        "\n",
        "fig = plt.figure(figsize=(14,10))\n",
        "\n",
        "label = 'Logistic Regression'\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X, y)\n",
        "\n",
        "fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
        "plt.title(label)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4b7UWS0P9LA"
      },
      "source": [
        "### Theory Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9ECO2HaQE7V"
      },
      "source": [
        "1. What Linear Regression training algorithm can you use if you have a training set\n",
        "with millions of features?\n",
        "\n",
        "  You could use batch gradient descent, stochastic gradient descent, or mini-batch gradient descent. SGD and MBGD would work the best because neither of them needs to load the entire dataset into memory in order to take 1 step of gradient descent. Batch would be ok with the caveat that you have enough memory to load all the data.\n",
        "\n",
        "  The normal equations method would not be a good choice because it is computationally inefficient. The main cause of the computational complexity comes from the inverse operation on an (n x n) matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfrFcYBQRZZs"
      },
      "source": [
        "2. Is it a good idea to stop Mini-batch Gradient Descent immediately when the validation error goes up?\n",
        "\n",
        "  Both Mini-batch and Stochastic gradient descent are not guaranteed to minimize the cost function after each step because they both have a degree of randomness built into them. Mini-bath randomly chooses which training examples to perform gradient descent on while Stochastic randomly chooses a single example. A better option is to save the model at regular intervals. When the model has not improved for a long time you can revert to the saved models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuEk-lSwQFB7"
      },
      "source": [
        "3. Can Gradient Descent get stuck in a local minimum when training a Logistic Regression model?\n",
        "\n",
        "  Gradient descent produces a convex-shaped graph that only has one global optimum. Therefore, it cannot get stuck in a local minimum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBD2xCOIQFFj"
      },
      "source": [
        "4. Do all Gradient Descent algorithms lead to the same model provided you let them run long enough?\n",
        "\n",
        "  No. The issue is that stochastic gradient descent and mini-batch gradient descent have randomness built into them. This means that they can find their way to nearby the global optimum, but they generally don't converge. One way to help them converge is to gradually reduce the learning rate hyperparameter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjh_NvoqQFI-"
      },
      "source": [
        "5. Suppose you want to classify pictures as outdoor/indoor and daytime/nighttime, should you implement two Logistic Regression classifiers or one Softmax Regression classifier?\n",
        "\n",
        "  Softmax regression does not handle multiple output classes (i.e. [indoor, daytime]). So you'll need to use two logistic regression classifiers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHfHdGCP_n6Y"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgSwVENIPcM6"
      },
      "source": [
        "#@title We are interested in reducing the number of false negatives. Which of the following metrics should we primarily look for? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"\" #@param [\"\", \"High Accuracy\", \"High Precision\", \"High Recall\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzAZHt1zw-Y-",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}