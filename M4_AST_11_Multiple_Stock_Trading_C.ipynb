{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M4_AST_11_Multiple_Stock_Trading_C.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilav/machinelearning/blob/main/M4_AST_11_Multiple_Stock_Trading_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZQMVE4gmAlY"
      },
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "## A program by IISc and TalentSprint\n",
        "### Assignment 11: Multiple Stock Trading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpgCEb9kmJ2Y"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZkwoKfWmNJj"
      },
      "source": [
        "At the end of the experiment, you will be able to\n",
        "\n",
        "* understand deep reinforcement learning\n",
        "* design an automated trading solution for multiple stock trading\n",
        "* backtest the trading results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn5uh0gT8t0d"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The dataset we use in this experiment is **Dow 30 constituents stocks** which is a price-weighted measurement stock market index of 30 prominent companies listed on stock exchanges in the United States. Companies included in this dataset are Apple Inc. (AAPL), Boeing (BA), Goldman Sachs (GS), etc.\n",
        "\n",
        "The data is obtained from Yahoo Finance API using YahooDownloader class. Yahoo Finance provides stock data, financial news, financial reports, etc for free. The data contains 46470 records and 8 columns including date,  Open, High, Low, Close stock price, volume, day, and tic (label of company stock).\n",
        "\n",
        "To know more about Dow 30 dataset, click [here](https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average#Components)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtdSVLWombeQ"
      },
      "source": [
        "## Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Owt2p3BXZLYM"
      },
      "source": [
        "**Deep reinforcement learning (DRL)** is a subfield of machine learning that combines reinforcement learning (RL) and deep learning. RL considers the problem of a computational agent learning to make decisions by trial and error. Deep RL incorporates deep learning into the solution, allowing agents to make decisions from unstructured input data without manual engineering of the state space.\n",
        "\n",
        "Suppose that we have a well trained DRL agent “DRL Trader”, we want to use it to **trade multiple stocks** in Dow 30 constituents portfolio:\n",
        "\n",
        "* Assume at the end of the day we are at time t, we will know the open-high-low-close price of the Dow 30 constituents stocks. We can use these information to calculate technical indicators such as MACD, RSI, CCI, ADX. In Reinforcement Learning, we call these data or features as “states”.\n",
        "\n",
        "* Portfolio value is given by \n",
        "\n",
        "$$V(t) =\\ balance (t) + dollar\\ amount\\ of\\ the\\ stocks (t).$$\n",
        "\n",
        "* We feed the states into our well trained DRL Trader, the trader will output a list of actions, the action for each stock is a value within $[-1, 1]$, we can treat this value as the trading signal, $1$ means a strong buy signal, $-1$ means a strong sell signal.\n",
        "\n",
        "* We calculate $$k = actions *h\\_max,$$ \n",
        "\n",
        " where $h\\_max$ is a predefined parameter that sets as the maximum amount of shares to trade. So we will have a list of shares to trade.\n",
        "\n",
        "* The dollar amount of $shares = shares\\ to\\ trade*\\ close\\ price (t)$.\n",
        "\n",
        "* Update balance and shares: These dollar amount of shares are the money we need to trade at time $t$.\n",
        "\n",
        "$$Updated\\ balance = balance(t)\\ −\\ amount\\ of\\ money\\ we\\ pay\\ to\\ buy\\ shares\\ +\\ amount\\ of\\ money\\ we\\ receive\\ to\\ sell\\ shares.$$ \n",
        "\n",
        "$$Updated\\ shares\\ =\\ shares\\ held(t) −\\ shares\\ to\\ sell\\ +\\ shares\\ to\\ buy$$.\n",
        "\n",
        "* So we take actions to trade based on the advice of our DRL Trader at the end of day at time $t$ (time $t$’s close price equals time $t+1$’s open price). We hope that we will benefit from these actions by the end of day at time $t+1$.\n",
        "\n",
        "* Take a step to time $t+1$, at the end of day, we will know the close price at $t+1$, the \n",
        "\n",
        "$$dollar\\ amount\\ of\\ the\\ stocks(t+1)\\ =\\ sum(updated\\ shares\\ * close\\ price (t+1)).$$ \n",
        "\n",
        "$$Portfolio\\ value V(t+1)\\ =\\ balance(t+1)\\ +\\ dollar\\ amount\\ of\\ the\\ stocks (t+1).$$\n",
        "\n",
        "* So the step reward by taking the actions from DRL Trader at time $t$ to $t+1$ is \n",
        "$$r = V(t+1) − V(t).$$ \n",
        "\n",
        " The reward can be positive or negative in the training stage. But we need a positive reward in trading to say that our DRL Trader is effective.\n",
        "\n",
        "* Repeat this process until termination.\n",
        "\n",
        "In the below figure we have the logic chart of multiple stock trading and a made-up example for demonstration purpose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi5gf6S4ZrUB"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/1902/1*wa0y8XkfswFABFjrMF5cFA.jpeg\"/ width=400px>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEtZsQCwhiOj"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/4098/1*gEmURZ0l7dgoj5p5N5wfLQ.png\"/ width=900px>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUvdTPgwaPGs"
      },
      "source": [
        "Multiple stock trading is different from single stock trading because as the number of stocks increases, the dimension of the data will increase, the state and action space in reinforcement learning will grow exponentially. So stability and reproducibility are very essential here.\n",
        "\n",
        "We use a DRL library `FinRL` that facilitates us in quantitative finance and to develop our own stock trading strategies.\n",
        "\n",
        "`FinRL` is characterized by its reproducibility, scalability, simplicity, applicability and extendibility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPi7cuH2aTwb"
      },
      "source": [
        "### Problem Statement \n",
        "\n",
        "Design an automated trading solution for multiple stock trading.\n",
        "\n",
        "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a Markov Decision Process (MDP) problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
        "\n",
        "The components of the reinforcement learning environment are:\n",
        "\n",
        "<center>\n",
        "<img src=\"https://www.kdnuggets.com/images/reinforcement-learning-fig1-700.jpg\" width=500px/>\n",
        "</center>\n",
        "\n",
        "* **Action:** The action space describes the allowed actions that the agent interacts with the environment. Normally, an action includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. When an action is carried upon multiple shares, we use an action space $\\{−k, …, −1, 0, 1, …, k\\}$, where $k$ denotes the number of shares to buy and $-k$ denotes the number of shares to sell. For 30 stocks the entire action space is $(2k+1)^{30}$, here we use $k ≤ h\\_max = 100$, so the entire action space is around $10^{60}$. It means we can sample a maximum of $10^{60}$ pairs of state and action combinations.\n",
        "\n",
        "* **State:** {balance, close price, shares, MACD, RSI, CCI, ADX}, 181-dimensional vector (30 stocks * 6 + 1)\n",
        "\n",
        "* **Reward function:** r(s, a, s′) = v′ − v, where v′ and v represent the portfolio values at state s′ and s, respectively\n",
        "\n",
        "* **Environment:** multiple stock trading for Dow 30 constituents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YzfoPvJDiTX"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjoZJWGErxGf"
      },
      "source": [
        "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBPPuGmBlDIN",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "  \n",
        "notebook= \"M4_AST_11_Multiple_Stock_Trading_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")  \n",
        "    ipython.magic(\"sx pip -qq install git+https://github.com/AI4Finance-LLC/FinRL-Library.git\")\n",
        "    ipython.magic(\"sx wget https://cdn.iisc.talentsprint.com/CDS/MiniProjects/dow_30_dataset.csv\")\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "    \n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None        \n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "    \n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None   \n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://cds.iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "    \n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional: \n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional  \n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "  \n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "  \n",
        "  \n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "  \n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError \n",
        "    else: \n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getId():\n",
        "  try: \n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup \n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup() \n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2MqLi0XacJX"
      },
      "source": [
        "### Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIV6nrRN6EMA"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import datetime\n",
        "import os\n",
        "from finrl import config\n",
        "from finrl import config_tickers\n",
        "from finrl.finrl_meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.finrl_meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfb1jR1OanOO"
      },
      "source": [
        "### Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooi1fVVRHvJq"
      },
      "source": [
        "# List of stock tickers\n",
        "print(config_tickers.DOW_30_TICKER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPCvskXPJ9WP"
      },
      "source": [
        "# Load dataset\n",
        "data_df = pd.read_csv(\"dow_30_dataset.csv\")\n",
        "data_df.sort_values(['date','tic'],ignore_index=True).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVLYFV1A6Cp9"
      },
      "source": [
        "data_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIDOqaxzazni"
      },
      "source": [
        "### Preprocess Data\n",
        "\n",
        "FinRL uses a `FeatureEngineer` class to preprocess data.\n",
        "\n",
        "Some of the technical indicators used in the analysis of financial markets include relative strength index (RSI), moving average convergence divergence (MACD), commodity channel index (CCI), and directional index (DX)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tech_indicator_list = config.INDICATORS\n",
        "print(tech_indicator_list)"
      ],
      "metadata": {
        "id": "Y-n1PQNzxg19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HwW_dWOK0Nn"
      },
      "source": [
        "# Perform Feature Engineering\n",
        "\n",
        "fe = FeatureEngineer(\n",
        "                    use_technical_indicator=True,\n",
        "                    tech_indicator_list = tech_indicator_list,\n",
        "                    use_turbulence=False,\n",
        "                    user_defined_feature = False)\n",
        "\n",
        "data_df = fe.preprocess_data(data_df)\n",
        "data_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3V03Mkja8CX"
      },
      "source": [
        "### Train & Trade Data Split\n",
        "\n",
        "In real life trading, the model needs to be updated periodically using rolling windows. Here, we just slice the data once into the train and trade set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rksm1NoA7A0N"
      },
      "source": [
        "# Train and trade data\n",
        "train = data_split(data_df, start = '2009-01-01', end = '2014-01-01')\n",
        "trade = data_split(data_df, start = '2014-01-01', end = '2015-03-01')\n",
        "# Check the length of the two datasets\n",
        "print(len(train))\n",
        "print(len(trade))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZqfu4aHa-2r"
      },
      "source": [
        "### Build Environment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute State Space and Action Space\n",
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(config.INDICATORS)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ],
      "metadata": {
        "id": "CeWRgPsr3N96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New\n",
        "buy_cost_list = [0.001] * stock_dimension\n",
        "sell_cost_list = [0.001] * stock_dimension\n",
        "num_stock_shares = [0] * stock_dimension\n",
        "\n",
        "# Initialize an environment class\n",
        "env_kwargs = {\n",
        "    \"hmax\": 100,                                                # max number of share purchases allowed per asset\n",
        "    \"initial_amount\": 1000000,                                  # amount of cash initially available\n",
        "    \"buy_cost_pct\": buy_cost_list,                              # cost for buying shares\n",
        "    \"sell_cost_pct\": sell_cost_list,                            # cost for selling shares\n",
        "    \"state_space\": state_space,                                 # contains all of the environment’s data to be observed by the agent\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"num_stock_shares\": num_stock_shares, \n",
        "    \"tech_indicator_list\": config.INDICATORS, \n",
        "    \"action_space\": stock_dimension,                            # contain all of the actions possible for an agent to take in the environment\n",
        "    \"reward_scaling\": 1e-4 }                                    # scaling value to multiply reward by at each step\n",
        "\n",
        "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "print(type(env_train))"
      ],
      "metadata": {
        "id": "gVBr6P0m3R1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfPUcFg3OPt1"
      },
      "source": [
        "Here , the action space is just the number of unique stocks i.e, 30 and the state space is 181."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgRy5e8GbU29"
      },
      "source": [
        "### Implement DRL Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w5hOTP4bZLE"
      },
      "source": [
        "`FinRL` library includes fine-tuned standard DRL algorithms, such as DQN, DDPG, PPO, SAC, A2C and TD3. It also allows users to design their own DRL algorithms by adapting these DRL algorithms. We use Soft Actor-Critic (SAC) for multiple stock trading because it is one of the most recent state-of-art algorithms. SAC is featured by its stability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9clEHa4WN-33"
      },
      "source": [
        "# Train SAC Model\n",
        "agent = DRLAgent(env = env_train)\n",
        "SAC_PARAMS = {\n",
        "    \"batch_size\": 128,\n",
        "    \"buffer_size\": 100000,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"learning_starts\": 200,\n",
        "    \"ent_coef\": \"auto_0.1\"\n",
        "}\n",
        "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
        "trained_sac = agent.train_model(model=model_sac, \n",
        "                             tb_log_name='sac',\n",
        "                             total_timesteps=30000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAdIPZZgbkoa"
      },
      "source": [
        "### Trading\n",
        "\n",
        "Assume that we have $1,000,000 initial capital on 2014/01/01. We use the SAC model to trade the Dow 30 stocks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhIUv5oN8IqN"
      },
      "source": [
        "# Trade data\n",
        "trade.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FWQ49dw8InU"
      },
      "source": [
        "# Create trading env\n",
        "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)\n",
        "\n",
        "# Make prediction and get the account value change\n",
        "df_account_value, df_actions = DRLAgent.DRL_prediction(model = trained_sac, environment = e_trade_gym)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv67F511PrH2"
      },
      "source": [
        "df_account_value.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZmp-UQlbt0j"
      },
      "source": [
        "### Backtesting Performance\n",
        "\n",
        "Backtesting plays a key role in evaluating the performance of a trading strategy. Backtesting assesses the viability of a trading strategy by discovering how it would perform on historical data. If backtesting works, traders and analysts may have increased confidence to employ it going forward. Automated backtesting tool is preferred because it reduces human error.\n",
        "\n",
        "`FinRL` uses a set of functions to do the backtesting with [Quantopian pyfolio](https://github.com/quantopian/pyfolio) package. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV2zodCX8MC9"
      },
      "source": [
        "# BackTestStats\n",
        "perf_stats_all = backtest_stats(account_value = df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PQnhnZhb0x1"
      },
      "source": [
        "The above table shows the statistics for backtesting performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25anXQwCRgH2"
      },
      "source": [
        "# Baseline stats\n",
        "baseline_df = get_baseline(ticker = '^DJI',\n",
        "                            start = '2014-01-01',\n",
        "                            end = '2015-03-01')\n",
        "stats = backtest_stats(baseline_df, value_col_name = 'close')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xUcxBQWSsCx"
      },
      "source": [
        "The above table shows the statistics for Dow Jones Industrial Average (DJIA) performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZkGiMEi8TsM"
      },
      "source": [
        "# BackTestPlot\n",
        "%matplotlib inline\n",
        "backtest_plot(account_value = df_account_value,     # pass the account value memory into the backtest functions\n",
        "              baseline_ticker = '^DJI',             # select a baseline ticker Dow Jones Index: ^DJI, S&P 500: ^GSPC, NASDAQ 100: ^NDX\n",
        "              baseline_start = '2014-01-01', \n",
        "              baseline_end = '2015-03-01')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0eTTvZQE9yu"
      },
      "source": [
        "In the above results, we can see \n",
        "\n",
        "* the statistics of the backtest along with drawdown period information\n",
        "\n",
        " A drawdown is a peak-to-valley decline during a specific period for an investment, trading account, or fund. A drawdown is usually quoted as the percentage between the peak and the subsequent valley. If a trading account has 10,000 in it, and the funds drop to 9,000 before moving back above 10,000, then the trading account witnessed a 10% drawdown. \n",
        " \n",
        " To know more about drawdown, click [here](https://www.investopedia.com/terms/d/drawdown.asp).\n",
        "\n",
        "* cumulative returns for daily return and backtest\n",
        "\n",
        "* cumulative returns volatility matched to benchmark\n",
        "\n",
        "* cumulative returns on logarithmic scale\n",
        "\n",
        "* top 5 drawdown periods\n",
        "\n",
        "* drawdown underwater plot\n",
        "\n",
        " Drawdowns are positive values. By simply reflecting the drawdowns across the x-axis we can turn this into an underwater plot as shown in the figure below.\n",
        "\n",
        " <center>\n",
        "<img src=\"https://www.researchgate.net/profile/Edwin-Fischer-2/publication/228828261/figure/fig2/AS:667775940964357@1536221599397/Maximum-Drawdown-and-Time-under-Water.png\" width=650px/>\n",
        "</center>\n",
        "\n",
        "* daily, weekly, and monthly return quantiles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXkTD2jUbfFO"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53jmsxGUbfFP"
      },
      "source": [
        "#@title Select the correct statement w.r.t. the advantages of using Deep Reinforcement Learning (DRL) for automated stock trading: { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"\" #@param [\"\", \"The goal of stock trading is to maximize returns while avoiding risks. DRL solves this optimization problem by maximizing the expected total reward from future actions over a time period\", \"DRL uses a reward function to optimize future rewards, in contrast to an ML regression/classification model that predicts the probability of future outcomes\", \"In contrast to Q-learning, that fails to handle large space, DRL is an efficient function approximator that can handle extremely large state space space and action space\", \"All the above\", \"None of the above\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6Dzmc0ebfFR"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pw_3v1cbfFR"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlS-QJ2YbfFS"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZlkigVibfFS"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J-i49gobfFT"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "-12NSgkNbfFT"
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hvX46wzM72Hb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}